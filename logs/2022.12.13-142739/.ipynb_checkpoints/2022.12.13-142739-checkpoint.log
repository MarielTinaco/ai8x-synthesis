2022-12-13 14:27:39,231 - Log file for this run: /home/ec2-user/SageMaker/pcd-max/training/logs/2022.12.13-142739/2022.12.13-142739.log
2022-12-13 14:27:43,895 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2022-12-13 14:27:43,895 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}
2022-12-13 14:27:43,955 - Dataset sizes:
	training=3592
	validation=399
	test=908
2022-12-13 14:27:43,955 - Reading compression schedule from: policies/schedule-for50epochs.yaml
2022-12-13 14:27:43,962 - 

2022-12-13 14:27:43,963 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:28:36,454 - Epoch: [0][   29/   29]    Overall Loss 1.955253    Objective Loss 1.955253    Top1 60.294118    Top5 89.705882    LR 0.001000    Time 1.809975    
2022-12-13 14:28:36,688 - --- validate (epoch=0)-----------
2022-12-13 14:28:36,688 - 399 samples (128 per mini-batch)
2022-12-13 14:28:43,312 - Epoch: [0][    4/    4]    Loss 2.288871    Top1 10.025063    Top5 58.145363    
2022-12-13 14:28:43,382 - ==> Top1: 10.025    Top5: 58.145    Loss: 2.289

2022-12-13 14:28:43,383 - ==> Confusion:
[[ 0  0  0  0  0 13  0  0  0  0]
 [ 0  0  0  0  0 56  0  0  0  0]
 [ 0  0  0  0  0 89  0  0  0  0]
 [ 0  0  0  0  0 20  0  0  0  0]
 [ 0  0  0  0  0 14  0  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  0 23  0  0  0  0]
 [ 0  0  0  0  0 67  0  0  0  0]
 [ 0  0  0  0  0 43  0  0  0  0]
 [ 0  0  0  0  0 34  0  0  0  0]]

2022-12-13 14:28:43,696 - ==> Best [Top1: 10.025   Top5: 58.145   Sparsity:0.00   Params: 369984 on epoch: 0]
2022-12-13 14:28:43,696 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:28:43,720 - 

2022-12-13 14:28:43,720 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:29:37,593 - Epoch: [1][   29/   29]    Overall Loss 1.471302    Objective Loss 1.471302    Top1 67.647059    Top5 94.117647    LR 0.001000    Time 1.857597    
2022-12-13 14:29:37,826 - --- validate (epoch=1)-----------
2022-12-13 14:29:37,826 - 399 samples (128 per mini-batch)
2022-12-13 14:29:44,435 - Epoch: [1][    4/    4]    Loss 2.296807    Top1 10.025063    Top5 65.664160    
2022-12-13 14:29:44,507 - ==> Top1: 10.025    Top5: 65.664    Loss: 2.297

2022-12-13 14:29:44,508 - ==> Confusion:
[[ 0  0  0  0  0 13  0  0  0  0]
 [ 0  0  0  0  0 56  0  0  0  0]
 [ 0  0  0  0  0 89  0  0  0  0]
 [ 0  0  0  0  0 20  0  0  0  0]
 [ 0  0  0  0  0 14  0  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  0 23  0  0  0  0]
 [ 0  0  0  0  0 67  0  0  0  0]
 [ 0  0  0  0  0 43  0  0  0  0]
 [ 0  0  0  0  0 34  0  0  0  0]]

2022-12-13 14:29:44,807 - ==> Best [Top1: 10.025   Top5: 65.664   Sparsity:0.00   Params: 369984 on epoch: 1]
2022-12-13 14:29:44,808 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:29:44,847 - 

2022-12-13 14:29:44,847 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:30:36,834 - Epoch: [2][   29/   29]    Overall Loss 1.162135    Objective Loss 1.162135    Top1 65.441176    Top5 91.911765    LR 0.001000    Time 1.792567    
2022-12-13 14:30:37,070 - --- validate (epoch=2)-----------
2022-12-13 14:30:37,070 - 399 samples (128 per mini-batch)
2022-12-13 14:30:43,724 - Epoch: [2][    4/    4]    Loss 2.322438    Top1 10.025063    Top5 49.874687    
2022-12-13 14:30:43,791 - ==> Top1: 10.025    Top5: 49.875    Loss: 2.322

2022-12-13 14:30:43,792 - ==> Confusion:
[[ 0  0  0  0  0 13  0  0  0  0]
 [ 0  0  0  0  0 56  0  0  0  0]
 [ 0  0  0  0  0 89  0  0  0  0]
 [ 0  0  0  0  0 20  0  0  0  0]
 [ 0  0  0  0  0 14  0  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  0 23  0  0  0  0]
 [ 0  0  0  0  0 67  0  0  0  0]
 [ 0  0  0  0  0 43  0  0  0  0]
 [ 0  0  0  0  0 34  0  0  0  0]]

2022-12-13 14:30:44,090 - ==> Best [Top1: 10.025   Top5: 65.664   Sparsity:0.00   Params: 369984 on epoch: 1]
2022-12-13 14:30:44,090 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:30:44,120 - 

2022-12-13 14:30:44,120 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:31:35,855 - Epoch: [3][   29/   29]    Overall Loss 0.962995    Objective Loss 0.962995    Top1 75.000000    Top5 98.529412    LR 0.001000    Time 1.783888    
2022-12-13 14:31:36,096 - --- validate (epoch=3)-----------
2022-12-13 14:31:36,097 - 399 samples (128 per mini-batch)
2022-12-13 14:31:42,719 - Epoch: [3][    4/    4]    Loss 2.561261    Top1 10.025063    Top5 61.403509    
2022-12-13 14:31:42,790 - ==> Top1: 10.025    Top5: 61.404    Loss: 2.561

2022-12-13 14:31:42,791 - ==> Confusion:
[[ 0  0  0  0  0 13  0  0  0  0]
 [ 0  0  0  0  0 56  0  0  0  0]
 [ 0  0  0  0  0 89  0  0  0  0]
 [ 0  0  0  0  0 20  0  0  0  0]
 [ 0  0  0  0  0 14  0  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  0 23  0  0  0  0]
 [ 0  0  0  0  0 67  0  0  0  0]
 [ 0  0  0  0  0 43  0  0  0  0]
 [ 0  0  0  0  0 34  0  0  0  0]]

2022-12-13 14:31:43,089 - ==> Best [Top1: 10.025   Top5: 65.664   Sparsity:0.00   Params: 369984 on epoch: 1]
2022-12-13 14:31:43,089 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:31:43,117 - 

2022-12-13 14:31:43,117 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:32:37,433 - Epoch: [4][   29/   29]    Overall Loss 0.809545    Objective Loss 0.809545    Top1 77.205882    Top5 96.323529    LR 0.001000    Time 1.872887    
2022-12-13 14:32:37,700 - --- validate (epoch=4)-----------
2022-12-13 14:32:37,701 - 399 samples (128 per mini-batch)
2022-12-13 14:32:44,347 - Epoch: [4][    4/    4]    Loss 0.798341    Top1 77.192982    Top5 96.491228    
2022-12-13 14:32:44,420 - ==> Top1: 77.193    Top5: 96.491    Loss: 0.798

2022-12-13 14:32:44,420 - ==> Confusion:
[[ 0  0  0  0  0  2  0  8  3  0]
 [ 0 51  0  0  0  0  0  2  3  0]
 [ 0  2 84  0  0  0  0  0  2  1]
 [ 0  1  0  0  0  2  0  1 16  0]
 [ 0  0  0  0  0 13  0  0  0  1]
 [ 0  0  0  0  0 39  0  1  0  0]
 [ 0  2  0  0  0 16  1  0  4  0]
 [ 0  2  1  0  0  1  0 62  0  1]
 [ 0  0  1  0  0  0  0  3 39  0]
 [ 0  0  1  0  0  1  0  0  0 32]]

2022-12-13 14:32:44,723 - ==> Best [Top1: 77.193   Top5: 96.491   Sparsity:0.00   Params: 369984 on epoch: 4]
2022-12-13 14:32:44,724 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:32:44,764 - 

2022-12-13 14:32:44,764 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:33:36,860 - Epoch: [5][   29/   29]    Overall Loss 0.650485    Objective Loss 0.650485    Top1 85.294118    Top5 99.264706    LR 0.001000    Time 1.796335    
2022-12-13 14:33:37,105 - --- validate (epoch=5)-----------
2022-12-13 14:33:37,105 - 399 samples (128 per mini-batch)
2022-12-13 14:33:43,745 - Epoch: [5][    4/    4]    Loss 0.621335    Top1 80.701754    Top5 97.243108    
2022-12-13 14:33:43,820 - ==> Top1: 80.702    Top5: 97.243    Loss: 0.621

2022-12-13 14:33:43,820 - ==> Confusion:
[[ 0  3  1  0  0  0  0  2  2  5]
 [ 0 53  1  0  0  0  0  0  2  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0  0  0  0  1  0 19  0]
 [ 0  0  0  0  5  6  2  0  1  0]
 [ 0  1  0  0  0 39  0  0  0  0]
 [ 0  1  0  0  5  2  9  0  6  0]
 [ 0  4  1  0  0  1  0 61  0  0]
 [ 0  2  3  0  0  0  0  0 38  0]
 [ 0  0  3  0  0  2  0  0  0 29]]

2022-12-13 14:33:44,123 - ==> Best [Top1: 80.702   Top5: 97.243   Sparsity:0.00   Params: 369984 on epoch: 5]
2022-12-13 14:33:44,123 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:33:44,161 - 

2022-12-13 14:33:44,161 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:34:36,206 - Epoch: [6][   29/   29]    Overall Loss 0.591452    Objective Loss 0.591452    Top1 84.558824    Top5 98.529412    LR 0.001000    Time 1.794576    
2022-12-13 14:34:36,438 - --- validate (epoch=6)-----------
2022-12-13 14:34:36,439 - 399 samples (128 per mini-batch)
2022-12-13 14:34:43,052 - Epoch: [6][    4/    4]    Loss 0.788751    Top1 74.436090    Top5 97.744361    
2022-12-13 14:34:43,127 - ==> Top1: 74.436    Top5: 97.744    Loss: 0.789

2022-12-13 14:34:43,128 - ==> Confusion:
[[ 0  0  0  0  0  2  0  1  9  1]
 [ 0 53  0  0  0  0  0  0  3  0]
 [ 0  2 50  0  1  0  0  0 29  7]
 [ 0  0  0  0  0  0  2  0 18  0]
 [ 0  0  0  0  5  2  7  0  0  0]
 [ 0  0  0  0  2 38  0  0  0  0]
 [ 0  0  0  0  3  0 17  0  3  0]
 [ 0  1  0  0  0  0  0 62  4  0]
 [ 0  1  0  0  0  0  0  0 42  0]
 [ 0  0  0  0  1  2  0  0  1 30]]

2022-12-13 14:34:43,431 - ==> Best [Top1: 80.702   Top5: 97.243   Sparsity:0.00   Params: 369984 on epoch: 5]
2022-12-13 14:34:43,431 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:34:43,458 - 

2022-12-13 14:34:43,459 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:35:37,256 - Epoch: [7][   29/   29]    Overall Loss 0.544317    Objective Loss 0.544317    Top1 87.500000    Top5 100.000000    LR 0.001000    Time 1.854992    
2022-12-13 14:35:37,505 - --- validate (epoch=7)-----------
2022-12-13 14:35:37,505 - 399 samples (128 per mini-batch)
2022-12-13 14:35:44,125 - Epoch: [7][    4/    4]    Loss 0.622099    Top1 82.456140    Top5 98.997494    
2022-12-13 14:35:44,202 - ==> Top1: 82.456    Top5: 98.997    Loss: 0.622

2022-12-13 14:35:44,202 - ==> Confusion:
[[ 0  0  0  1  0  0  0  5  6  1]
 [ 0 50  0  0  0  0  0  2  4  0]
 [ 0  2 85  0  0  0  0  0  2  0]
 [ 0  0  0  0  0  0  3  0 17  0]
 [ 0  0  0  0  3  2  9  0  0  0]
 [ 0  0  0  0  0 39  0  1  0  0]
 [ 0  0  0  0  2  1 18  0  2  0]
 [ 0  0  0  0  0  1  0 66  0  0]
 [ 0  0  0  0  0  0  0  2 41  0]
 [ 0  1  3  0  1  2  0  0  0 27]]

2022-12-13 14:35:44,503 - ==> Best [Top1: 82.456   Top5: 98.997   Sparsity:0.00   Params: 369984 on epoch: 7]
2022-12-13 14:35:44,503 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:35:44,540 - 

2022-12-13 14:35:44,540 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:36:36,864 - Epoch: [8][   29/   29]    Overall Loss 0.461661    Objective Loss 0.461661    Top1 87.500000    Top5 100.000000    LR 0.001000    Time 1.804191    
2022-12-13 14:36:37,079 - --- validate (epoch=8)-----------
2022-12-13 14:36:37,079 - 399 samples (128 per mini-batch)
2022-12-13 14:36:43,730 - Epoch: [8][    4/    4]    Loss 0.580174    Top1 79.699248    Top5 97.994987    
2022-12-13 14:36:43,806 - ==> Top1: 79.699    Top5: 97.995    Loss: 0.580

2022-12-13 14:36:43,806 - ==> Confusion:
[[ 0  0  0  0  0  3  0  3  0  7]
 [ 0 50  0  1  0  0  0  2  1  2]
 [ 0  1 80  0  0  1  0  0  0  7]
 [ 0  0  1  4  2  1  1  1  7  3]
 [ 0  0  0  0  8  5  1  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0 12  3  8  0  0  0]
 [ 0  1  0  0  0  4  0 62  0  0]
 [ 0  1  3  1  0  0  0  3 34  1]
 [ 0  0  0  0  0  2  0  0  0 32]]

2022-12-13 14:36:44,111 - ==> Best [Top1: 82.456   Top5: 98.997   Sparsity:0.00   Params: 369984 on epoch: 7]
2022-12-13 14:36:44,111 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:36:44,139 - 

2022-12-13 14:36:44,140 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:37:36,124 - Epoch: [9][   29/   29]    Overall Loss 0.402613    Objective Loss 0.402613    Top1 91.176471    Top5 100.000000    LR 0.001000    Time 1.792470    
2022-12-13 14:37:36,344 - --- validate (epoch=9)-----------
2022-12-13 14:37:36,345 - 399 samples (128 per mini-batch)
2022-12-13 14:37:42,965 - Epoch: [9][    4/    4]    Loss 0.465097    Top1 84.210526    Top5 99.248120    
2022-12-13 14:37:43,036 - ==> Top1: 84.211    Top5: 99.248    Loss: 0.465

2022-12-13 14:37:43,037 - ==> Confusion:
[[ 0  0  1  1  0  0  0  1  8  2]
 [ 0 53  1  0  0  0  0  0  2  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  2  0  0  0  2  0 16  0]
 [ 0  0  0  0  6  1  7  0  0  0]
 [ 0  0  0  0  2 37  0  1  0  0]
 [ 0  0  0  1  1  0 20  0  1  0]
 [ 0  1  0  1  0  0  0 63  2  0]
 [ 0  0  2  0  0  0  0  0 41  0]
 [ 0  0  5  0  0  0  1  0  0 28]]

2022-12-13 14:37:43,338 - ==> Best [Top1: 84.211   Top5: 99.248   Sparsity:0.00   Params: 369984 on epoch: 9]
2022-12-13 14:37:43,338 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:37:43,375 - 

2022-12-13 14:37:43,375 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:38:36,996 - Epoch: [10][   29/   29]    Overall Loss 0.336555    Objective Loss 0.336555    Top1 90.441176    Top5 100.000000    LR 0.000100    Time 1.848906    
2022-12-13 14:38:37,223 - --- validate (epoch=10)-----------
2022-12-13 14:38:37,223 - 399 samples (128 per mini-batch)
2022-12-13 14:38:43,830 - Epoch: [10][    4/    4]    Loss 0.391095    Top1 87.468672    Top5 99.498747    
2022-12-13 14:38:43,903 - ==> Top1: 87.469    Top5: 99.499    Loss: 0.391

2022-12-13 14:38:43,904 - ==> Confusion:
[[ 0  1  0  5  0  0  0  4  1  2]
 [ 0 54  0  0  0  0  0  0  2  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0  9  0  0  3  0  8  0]
 [ 0  0  0  0  7  1  6  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  8  0 15  0  0  0]
 [ 0  1  0  0  0  2  0 64  0  0]
 [ 0  0  1  0  0  0  0  1 41  0]
 [ 0  0  1  0  2  0  0  0  0 31]]

2022-12-13 14:38:44,206 - ==> Best [Top1: 87.469   Top5: 99.499   Sparsity:0.00   Params: 369984 on epoch: 10]
2022-12-13 14:38:44,206 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:38:44,244 - 

2022-12-13 14:38:44,244 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:39:36,314 - Epoch: [11][   29/   29]    Overall Loss 0.321186    Objective Loss 0.321186    Top1 87.500000    Top5 100.000000    LR 0.000100    Time 1.795431    
2022-12-13 14:39:36,541 - --- validate (epoch=11)-----------
2022-12-13 14:39:36,541 - 399 samples (128 per mini-batch)
2022-12-13 14:39:43,175 - Epoch: [11][    4/    4]    Loss 0.442490    Top1 87.969925    Top5 99.498747    
2022-12-13 14:39:43,251 - ==> Top1: 87.970    Top5: 99.499    Loss: 0.442

2022-12-13 14:39:43,252 - ==> Confusion:
[[ 0  1  0  4  0  0  0  5  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 10  1  0  2  0  7  0]
 [ 0  0  0  0  8  1  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  8  0 15  0  0  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  0  1  1  0  0  0  2 39  0]
 [ 0  1  0  0  1  0  0  0  0 32]]

2022-12-13 14:39:43,762 - ==> Best [Top1: 87.970   Top5: 99.499   Sparsity:0.00   Params: 369984 on epoch: 11]
2022-12-13 14:39:43,762 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:39:43,800 - 

2022-12-13 14:39:43,800 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:40:35,924 - Epoch: [12][   29/   29]    Overall Loss 0.303435    Objective Loss 0.303435    Top1 89.705882    Top5 100.000000    LR 0.000100    Time 1.797288    
2022-12-13 14:40:36,139 - --- validate (epoch=12)-----------
2022-12-13 14:40:36,139 - 399 samples (128 per mini-batch)
2022-12-13 14:40:42,777 - Epoch: [12][    4/    4]    Loss 0.402081    Top1 87.719298    Top5 99.749373    
2022-12-13 14:40:42,848 - ==> Top1: 87.719    Top5: 99.749    Loss: 0.402

2022-12-13 14:40:42,849 - ==> Confusion:
[[ 0  1  0  3  0  0  0  5  0  4]
 [ 0 53  1  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 10  1  0  1  0  8  0]
 [ 0  0  0  0  7  1  6  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  7  0 16  0  0  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  0  1  1  0  0  0  1 40  0]
 [ 0  1  1  0  1  0  0  0  0 31]]

2022-12-13 14:40:43,156 - ==> Best [Top1: 87.970   Top5: 99.499   Sparsity:0.00   Params: 369984 on epoch: 11]
2022-12-13 14:40:43,156 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:40:43,184 - 

2022-12-13 14:40:43,184 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:41:37,125 - Epoch: [13][   29/   29]    Overall Loss 0.297038    Objective Loss 0.297038    Top1 94.117647    Top5 100.000000    LR 0.000100    Time 1.859955    
2022-12-13 14:41:37,365 - --- validate (epoch=13)-----------
2022-12-13 14:41:37,365 - 399 samples (128 per mini-batch)
2022-12-13 14:41:44,052 - Epoch: [13][    4/    4]    Loss 0.411884    Top1 86.716792    Top5 99.498747    
2022-12-13 14:41:44,128 - ==> Top1: 86.717    Top5: 99.499    Loss: 0.412

2022-12-13 14:41:44,129 - ==> Confusion:
[[ 0  1  0  3  0  0  0  6  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 11  1  0  1  0  7  0]
 [ 0  0  0  0  7  3  4  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0 10  0 13  0  0  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  1  2  2  0  0  0  1 37  0]
 [ 0  1  1  0  1  0  0  0  0 31]]

2022-12-13 14:41:44,432 - ==> Best [Top1: 87.970   Top5: 99.499   Sparsity:0.00   Params: 369984 on epoch: 11]
2022-12-13 14:41:44,432 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:41:44,460 - 

2022-12-13 14:41:44,460 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:42:36,489 - Epoch: [14][   29/   29]    Overall Loss 0.275488    Objective Loss 0.275488    Top1 93.382353    Top5 99.264706    LR 0.000100    Time 1.794026    
2022-12-13 14:42:36,739 - --- validate (epoch=14)-----------
2022-12-13 14:42:36,740 - 399 samples (128 per mini-batch)
2022-12-13 14:42:43,416 - Epoch: [14][    4/    4]    Loss 0.357331    Top1 86.716792    Top5 99.498747    
2022-12-13 14:42:43,486 - ==> Top1: 86.717    Top5: 99.499    Loss: 0.357

2022-12-13 14:42:43,486 - ==> Confusion:
[[ 0  1  0  4  0  0  0  5  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 10  1  0  3  0  6  0]
 [ 0  0  0  0  6  2  6  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  8  0 15  0  0  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  1  1  3  0  0  0  1 37  0]
 [ 0  1  1  0  1  0  0  0  0 31]]

2022-12-13 14:42:43,788 - ==> Best [Top1: 87.970   Top5: 99.499   Sparsity:0.00   Params: 369984 on epoch: 11]
2022-12-13 14:42:43,788 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:42:43,816 - 

2022-12-13 14:42:43,816 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:43:35,993 - Epoch: [15][   29/   29]    Overall Loss 0.276681    Objective Loss 0.276681    Top1 91.176471    Top5 100.000000    LR 0.000100    Time 1.799101    
2022-12-13 14:43:36,247 - --- validate (epoch=15)-----------
2022-12-13 14:43:36,247 - 399 samples (128 per mini-batch)
2022-12-13 14:43:42,894 - Epoch: [15][    4/    4]    Loss 0.382770    Top1 87.218045    Top5 99.749373    
2022-12-13 14:43:42,968 - ==> Top1: 87.218    Top5: 99.749    Loss: 0.383

2022-12-13 14:43:42,969 - ==> Confusion:
[[ 0  1  0  4  0  0  0  5  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 87  0  0  0  0  0  0  1]
 [ 0  0  0 11  1  0  1  0  7  0]
 [ 0  0  0  0  6  2  6  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  8  0 14  0  1  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  0  1  2  0  0  0  1 39  0]
 [ 0  1  0  0  0  1  0  0  0 32]]

2022-12-13 14:43:43,272 - ==> Best [Top1: 87.970   Top5: 99.499   Sparsity:0.00   Params: 369984 on epoch: 11]
2022-12-13 14:43:43,272 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:43:43,303 - 

2022-12-13 14:43:43,303 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:44:36,792 - Epoch: [16][   29/   29]    Overall Loss 0.309595    Objective Loss 0.309595    Top1 88.235294    Top5 98.529412    LR 0.000100    Time 1.844379    
2022-12-13 14:44:37,042 - --- validate (epoch=16)-----------
2022-12-13 14:44:37,042 - 399 samples (128 per mini-batch)
2022-12-13 14:44:43,628 - Epoch: [16][    4/    4]    Loss 0.436938    Top1 87.468672    Top5 99.749373    
2022-12-13 14:44:43,709 - ==> Top1: 87.469    Top5: 99.749    Loss: 0.437

2022-12-13 14:44:43,710 - ==> Confusion:
[[ 0  1  0  4  0  0  0  5  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 87  0  0  0  0  0  0  1]
 [ 0  0  0 12  1  0  3  0  4  0]
 [ 0  0  0  0  7  1  6  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  8  0 15  0  0  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  1  1  2  0  0  0  2 37  0]
 [ 0  0  0  0  2  0  0  0  0 32]]

2022-12-13 14:44:44,011 - ==> Best [Top1: 87.970   Top5: 99.499   Sparsity:0.00   Params: 369984 on epoch: 11]
2022-12-13 14:44:44,011 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:44:44,040 - 

2022-12-13 14:44:44,040 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:45:36,154 - Epoch: [17][   29/   29]    Overall Loss 0.275638    Objective Loss 0.275638    Top1 90.441176    Top5 100.000000    LR 0.000100    Time 1.796921    
2022-12-13 14:45:36,371 - --- validate (epoch=17)-----------
2022-12-13 14:45:36,372 - 399 samples (128 per mini-batch)
2022-12-13 14:45:42,982 - Epoch: [17][    4/    4]    Loss 0.358943    Top1 89.223058    Top5 99.749373    
2022-12-13 14:45:43,058 - ==> Top1: 89.223    Top5: 99.749    Loss: 0.359

2022-12-13 14:45:43,058 - ==> Confusion:
[[ 0  0  0  5  0  0  0  4  1  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 10  0  0  2  0  8  0]
 [ 0  0  0  0  7  1  6  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  3  0 19  0  1  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  1  1  0  0  0  0  0 41  0]
 [ 0  0  0  1  1  0  0  0  0 32]]

2022-12-13 14:45:43,359 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:45:43,359 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:45:43,398 - 

2022-12-13 14:45:43,398 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:46:35,694 - Epoch: [18][   29/   29]    Overall Loss 0.263467    Objective Loss 0.263467    Top1 94.117647    Top5 100.000000    LR 0.000100    Time 1.803233    
2022-12-13 14:46:35,929 - --- validate (epoch=18)-----------
2022-12-13 14:46:35,930 - 399 samples (128 per mini-batch)
2022-12-13 14:46:42,594 - Epoch: [18][    4/    4]    Loss 0.402909    Top1 88.972431    Top5 99.749373    
2022-12-13 14:46:42,665 - ==> Top1: 88.972    Top5: 99.749    Loss: 0.403

2022-12-13 14:46:42,666 - ==> Confusion:
[[ 0  1  0  4  0  0  0  4  0  4]
 [ 0 55  0  1  0  0  0  0  0  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 13  0  0  3  0  4  0]
 [ 0  0  0  0  7  1  6  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  5  0 17  0  1  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  1  1  3  0  0  0  1 37  0]
 [ 0  0  0  0  1  0  0  0  0 33]]

2022-12-13 14:46:42,973 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:46:42,973 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:46:43,000 - 

2022-12-13 14:46:43,000 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:47:36,875 - Epoch: [19][   29/   29]    Overall Loss 0.250958    Objective Loss 0.250958    Top1 94.117647    Top5 100.000000    LR 0.000100    Time 1.857661    
2022-12-13 14:47:37,117 - --- validate (epoch=19)-----------
2022-12-13 14:47:37,117 - 399 samples (128 per mini-batch)
2022-12-13 14:47:43,721 - Epoch: [19][    4/    4]    Loss 0.323052    Top1 86.716792    Top5 99.749373    
2022-12-13 14:47:43,792 - ==> Top1: 86.717    Top5: 99.749    Loss: 0.323

2022-12-13 14:47:43,792 - ==> Confusion:
[[ 0  0  0  4  0  0  0  6  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 86  0  0  0  1  0  0  1]
 [ 0  0  0 12  1  0  3  0  4  0]
 [ 0  0  0  0  6  3  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  9  0 13  0  1  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  1  1  2  0  0  0  2 37  0]
 [ 0  0  0  0  0  1  0  0  0 33]]

2022-12-13 14:47:44,100 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:47:44,101 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:47:44,128 - 

2022-12-13 14:47:44,128 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:48:36,027 - Epoch: [20][   29/   29]    Overall Loss 0.246938    Objective Loss 0.246938    Top1 92.647059    Top5 100.000000    LR 0.000100    Time 1.789540    
2022-12-13 14:48:36,259 - --- validate (epoch=20)-----------
2022-12-13 14:48:36,259 - 399 samples (128 per mini-batch)
2022-12-13 14:48:42,893 - Epoch: [20][    4/    4]    Loss 0.348650    Top1 88.471178    Top5 99.749373    
2022-12-13 14:48:42,967 - ==> Top1: 88.471    Top5: 99.749    Loss: 0.349

2022-12-13 14:48:42,967 - ==> Confusion:
[[ 0  0  0  5  0  0  0  5  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 13  0  0  4  0  3  0]
 [ 0  0  0  0  7  2  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  4  0 19  0  0  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  1  1  2  0  0  0  2 37  0]
 [ 0  0  2  1  0  1  0  0  0 30]]

2022-12-13 14:48:43,492 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:48:43,493 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:48:43,519 - 

2022-12-13 14:48:43,520 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:49:35,747 - Epoch: [21][   29/   29]    Overall Loss 0.247217    Objective Loss 0.247217    Top1 96.323529    Top5 100.000000    LR 0.000100    Time 1.800874    
2022-12-13 14:49:35,983 - --- validate (epoch=21)-----------
2022-12-13 14:49:35,983 - 399 samples (128 per mini-batch)
2022-12-13 14:49:42,603 - Epoch: [21][    4/    4]    Loss 0.313019    Top1 87.969925    Top5 99.749373    
2022-12-13 14:49:42,676 - ==> Top1: 87.970    Top5: 99.749    Loss: 0.313

2022-12-13 14:49:42,677 - ==> Confusion:
[[ 0  0  0  7  0  0  0  3  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 11  0  0  3  0  6  0]
 [ 0  0  0  0  6  2  6  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  3  0 18  0  1  0]
 [ 0  1  0  0  0  0  0 66  0  0]
 [ 0  0  1  3  0  0  0  1 38  0]
 [ 0  0  2  1  0  1  0  0  0 30]]

2022-12-13 14:49:42,978 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:49:42,978 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:49:43,007 - 

2022-12-13 14:49:43,007 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:50:37,026 - Epoch: [22][   29/   29]    Overall Loss 0.246723    Objective Loss 0.246723    Top1 92.647059    Top5 100.000000    LR 0.000100    Time 1.862652    
2022-12-13 14:50:37,256 - --- validate (epoch=22)-----------
2022-12-13 14:50:37,257 - 399 samples (128 per mini-batch)
2022-12-13 14:50:43,837 - Epoch: [22][    4/    4]    Loss 0.333259    Top1 87.719298    Top5 99.749373    
2022-12-13 14:50:43,908 - ==> Top1: 87.719    Top5: 99.749    Loss: 0.333

2022-12-13 14:50:43,909 - ==> Confusion:
[[ 0  0  0  6  0  0  0  4  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 85  0  0  0  1  0  0  2]
 [ 0  0  0 14  1  0  2  0  3  0]
 [ 0  0  0  0  9  2  3  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  8  0 15  0  0  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  1  1  3  0  0  0  1 37  0]
 [ 0  0  1  0  0  1  1  0  0 31]]

2022-12-13 14:50:44,210 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:50:44,210 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:50:44,239 - 

2022-12-13 14:50:44,239 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:51:36,390 - Epoch: [23][   29/   29]    Overall Loss 0.233415    Objective Loss 0.233415    Top1 93.382353    Top5 99.264706    LR 0.000100    Time 1.798208    
2022-12-13 14:51:36,626 - --- validate (epoch=23)-----------
2022-12-13 14:51:36,627 - 399 samples (128 per mini-batch)
2022-12-13 14:51:43,254 - Epoch: [23][    4/    4]    Loss 0.441130    Top1 88.220551    Top5 99.749373    
2022-12-13 14:51:43,324 - ==> Top1: 88.221    Top5: 99.749    Loss: 0.441

2022-12-13 14:51:43,324 - ==> Confusion:
[[ 0  0  0  6  0  0  0  4  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 86  0  0  0  1  0  0  1]
 [ 0  0  0 13  0  0  4  0  3  0]
 [ 0  0  0  0  9  1  4  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  5  0 18  0  0  0]
 [ 0  1  0  0  0  0  0 66  0  0]
 [ 0  1  1  3  0  0  0  2 36  0]
 [ 0  0  2  0  1  0  1  0  0 30]]

2022-12-13 14:51:43,625 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:51:43,625 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:51:43,652 - 

2022-12-13 14:51:43,653 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:52:35,634 - Epoch: [24][   29/   29]    Overall Loss 0.215766    Objective Loss 0.215766    Top1 97.794118    Top5 100.000000    LR 0.000100    Time 1.792380    
2022-12-13 14:52:35,871 - --- validate (epoch=24)-----------
2022-12-13 14:52:35,871 - 399 samples (128 per mini-batch)
2022-12-13 14:52:42,488 - Epoch: [24][    4/    4]    Loss 0.306178    Top1 88.721805    Top5 99.749373    
2022-12-13 14:52:42,560 - ==> Top1: 88.722    Top5: 99.749    Loss: 0.306

2022-12-13 14:52:42,561 - ==> Confusion:
[[ 1  0  0  5  0  0  0  4  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 86  0  0  0  1  0  0  1]
 [ 0  0  0 14  0  0  3  0  3  0]
 [ 0  0  0  0  7  2  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  4  0 18  0  0  0]
 [ 0  1  0  0  0  0  0 66  0  0]
 [ 0  2  1  2  0  0  0  2 36  0]
 [ 0  0  0  0  1  0  1  0  0 32]]

2022-12-13 14:52:42,859 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:52:42,860 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:52:42,888 - 

2022-12-13 14:52:42,888 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:53:36,518 - Epoch: [25][   29/   29]    Overall Loss 0.217818    Objective Loss 0.217818    Top1 97.058824    Top5 100.000000    LR 0.000100    Time 1.849226    
2022-12-13 14:53:36,741 - --- validate (epoch=25)-----------
2022-12-13 14:53:36,741 - 399 samples (128 per mini-batch)
2022-12-13 14:53:43,364 - Epoch: [25][    4/    4]    Loss 0.416733    Top1 87.969925    Top5 99.749373    
2022-12-13 14:53:43,436 - ==> Top1: 87.970    Top5: 99.749    Loss: 0.417

2022-12-13 14:53:43,437 - ==> Confusion:
[[ 3  0  0  4  0  0  0  3  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 86  0  0  0  1  0  0  1]
 [ 0  0  0 14  0  0  2  0  4  0]
 [ 0  0  0  0  9  2  3  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  8  0 13  0  1  0]
 [ 0  1  0  0  0  0  0 66  0  0]
 [ 0  2  1  3  0  0  0  2 35  0]
 [ 0  0  1  0  2  0  0  0  0 31]]

2022-12-13 14:53:43,737 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:53:43,737 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:53:43,764 - 

2022-12-13 14:53:43,765 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:54:35,686 - Epoch: [26][   29/   29]    Overall Loss 0.218414    Objective Loss 0.218414    Top1 94.117647    Top5 100.000000    LR 0.000100    Time 1.790288    
2022-12-13 14:54:35,927 - --- validate (epoch=26)-----------
2022-12-13 14:54:35,927 - 399 samples (128 per mini-batch)
2022-12-13 14:54:42,527 - Epoch: [26][    4/    4]    Loss 0.289825    Top1 88.972431    Top5 99.749373    
2022-12-13 14:54:42,597 - ==> Top1: 88.972    Top5: 99.749    Loss: 0.290

2022-12-13 14:54:42,597 - ==> Confusion:
[[ 1  0  0  5  0  0  0  4  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 87  0  0  0  1  0  0  0]
 [ 0  0  0 13  0  0  2  0  5  0]
 [ 0  0  0  0  9  1  4  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  4  0 17  0  1  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  1  1  2  0  0  0  1 38  0]
 [ 0  0  1  0  1  1  0  0  0 31]]

2022-12-13 14:54:42,895 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:54:42,895 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:54:42,923 - 

2022-12-13 14:54:42,924 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:55:35,231 - Epoch: [27][   29/   29]    Overall Loss 0.216040    Objective Loss 0.216040    Top1 95.588235    Top5 100.000000    LR 0.000100    Time 1.803593    
2022-12-13 14:55:35,460 - --- validate (epoch=27)-----------
2022-12-13 14:55:35,461 - 399 samples (128 per mini-batch)
2022-12-13 14:55:42,022 - Epoch: [27][    4/    4]    Loss 0.395796    Top1 88.972431    Top5 99.749373    
2022-12-13 14:55:42,093 - ==> Top1: 88.972    Top5: 99.749    Loss: 0.396

2022-12-13 14:55:42,094 - ==> Confusion:
[[ 2  0  0  3  0  0  0  5  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 85  0  0  0  1  0  0  2]
 [ 0  0  0 14  0  0  2  0  4  0]
 [ 0  0  0  0  6  3  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  3  0 19  0  0  0]
 [ 0  1  0  0  0  0  0 66  0  0]
 [ 0  2  1  2  0  0  0  2 36  0]
 [ 0  0  0  0  1  0  0  0  0 33]]

2022-12-13 14:55:42,392 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:55:42,392 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:55:42,420 - 

2022-12-13 14:55:42,420 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:56:36,201 - Epoch: [28][   29/   29]    Overall Loss 0.209907    Objective Loss 0.209907    Top1 96.323529    Top5 100.000000    LR 0.000100    Time 1.854424    
2022-12-13 14:56:36,418 - --- validate (epoch=28)-----------
2022-12-13 14:56:36,419 - 399 samples (128 per mini-batch)
2022-12-13 14:56:43,001 - Epoch: [28][    4/    4]    Loss 0.389019    Top1 89.223058    Top5 99.498747    
2022-12-13 14:56:43,076 - ==> Top1: 89.223    Top5: 99.499    Loss: 0.389

2022-12-13 14:56:43,076 - ==> Confusion:
[[ 1  0  0  8  0  0  0  2  0  2]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 87  0  0  0  1  0  0  0]
 [ 0  0  0 12  0  0  3  0  5  0]
 [ 0  0  0  0  9  0  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  3  0 19  0  0  0]
 [ 0  1  0  1  0  0  0 65  0  0]
 [ 0  0  1  2  0  0  0  1 39  0]
 [ 0  0  1  1  1  0  1  0  0 30]]

2022-12-13 14:56:43,377 - ==> Best [Top1: 89.223   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 17]
2022-12-13 14:56:43,377 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:56:43,405 - 

2022-12-13 14:56:43,405 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:57:35,543 - Epoch: [29][   29/   29]    Overall Loss 0.210164    Objective Loss 0.210164    Top1 97.058824    Top5 100.000000    LR 0.000100    Time 1.797775    
2022-12-13 14:57:35,785 - --- validate (epoch=29)-----------
2022-12-13 14:57:35,785 - 399 samples (128 per mini-batch)
2022-12-13 14:57:42,381 - Epoch: [29][    4/    4]    Loss 0.369136    Top1 89.724311    Top5 99.749373    
2022-12-13 14:57:42,454 - ==> Top1: 89.724    Top5: 99.749    Loss: 0.369

2022-12-13 14:57:42,455 - ==> Confusion:
[[ 2  0  0  4  0  0  0  4  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 87  0  0  0  1  0  0  0]
 [ 0  0  0 15  0  0  2  0  3  0]
 [ 0  0  0  0  9  2  3  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  5  0 18  0  0  0]
 [ 0  1  0  0  0  0  0 66  0  0]
 [ 0  2  2  3  0  0  0  1 35  0]
 [ 0  0  0  1  0  0  1  0  0 32]]

2022-12-13 14:57:42,986 - ==> Best [Top1: 89.724   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 29]
2022-12-13 14:57:42,986 - Saving checkpoint to: logs/2022.12.13-142739/checkpoint.pth.tar
2022-12-13 14:57:43,053 - 

2022-12-13 14:57:43,054 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:58:35,481 - Epoch: [30][   29/   29]    Overall Loss 0.087935    Objective Loss 0.087935    Top1 97.058824    Top5 100.000000    LR 0.000100    Time 1.807784    
2022-12-13 14:58:35,702 - --- validate (epoch=30)-----------
2022-12-13 14:58:35,702 - 399 samples (128 per mini-batch)
2022-12-13 14:58:42,395 - Epoch: [30][    4/    4]    Loss 0.337175    Top1 89.223058    Top5 100.000000    
2022-12-13 14:58:42,466 - ==> Top1: 89.223    Top5: 100.000    Loss: 0.337

2022-12-13 14:58:42,467 - ==> Confusion:
[[ 5  0  0  3  0  0  0  2  0  3]
 [ 0 55  0  1  0  0  0  0  0  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 12  0  0  4  0  4  0]
 [ 0  0  0  0  9  2  3  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  1  0  0  5  0 17  0  0  0]
 [ 0  1  0  0  0  1  0 65  0  0]
 [ 0  2  2  3  0  0  0  1 35  0]
 [ 0  0  2  0  1  1  0  0  0 30]]

2022-12-13 14:58:42,766 - ==> Best [Top1: 89.223   Top5: 100.000   Sparsity:0.00   Params: 369984 on epoch: 30]
2022-12-13 14:58:42,766 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 14:58:42,788 - 

2022-12-13 14:58:42,788 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 14:59:36,828 - Epoch: [31][   29/   29]    Overall Loss 0.084441    Objective Loss 0.084441    Top1 97.058824    Top5 100.000000    LR 0.000100    Time 1.863342    
2022-12-13 14:59:37,060 - --- validate (epoch=31)-----------
2022-12-13 14:59:37,060 - 399 samples (128 per mini-batch)
2022-12-13 14:59:43,750 - Epoch: [31][    4/    4]    Loss 0.407117    Top1 89.974937    Top5 99.498747    
2022-12-13 14:59:43,825 - ==> Top1: 89.975    Top5: 99.499    Loss: 0.407

2022-12-13 14:59:43,825 - ==> Confusion:
[[ 5  0  0  3  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 12  0  0  3  0  5  0]
 [ 0  0  0  0  9  0  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  3  0 20  0  0  0]
 [ 0  1  0  0  0  0  0 66  0  0]
 [ 0  2  1  3  0  0  0  1 36  0]
 [ 0  0  2  1  1  0  1  0  0 29]]

2022-12-13 14:59:44,127 - ==> Best [Top1: 89.975   Top5: 99.499   Sparsity:0.00   Params: 369984 on epoch: 31]
2022-12-13 14:59:44,127 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 14:59:44,161 - 

2022-12-13 14:59:44,161 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:00:36,292 - Epoch: [32][   29/   29]    Overall Loss 0.074860    Objective Loss 0.074860    Top1 95.588235    Top5 100.000000    LR 0.000100    Time 1.797555    
2022-12-13 15:00:36,516 - --- validate (epoch=32)-----------
2022-12-13 15:00:36,516 - 399 samples (128 per mini-batch)
2022-12-13 15:00:43,143 - Epoch: [32][    4/    4]    Loss 0.291394    Top1 90.225564    Top5 99.749373    
2022-12-13 15:00:43,221 - ==> Top1: 90.226    Top5: 99.749    Loss: 0.291

2022-12-13 15:00:43,222 - ==> Confusion:
[[ 5  0  0  4  0  0  0  2  0  2]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 13  0  0  2  0  5  0]
 [ 0  0  0  0  9  0  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  1  0  0  3  0 19  0  0  0]
 [ 0  1  0  0  0  0  0 66  0  0]
 [ 0  0  1  4  0  0  0  1 37  0]
 [ 0  0  2  1  0  1  1  0  0 29]]

2022-12-13 15:00:43,524 - ==> Best [Top1: 90.226   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 32]
2022-12-13 15:00:43,524 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:00:43,561 - 

2022-12-13 15:00:43,561 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:01:35,927 - Epoch: [33][   29/   29]    Overall Loss 0.065273    Objective Loss 0.065273    Top1 97.794118    Top5 100.000000    LR 0.000100    Time 1.805656    
2022-12-13 15:01:36,144 - --- validate (epoch=33)-----------
2022-12-13 15:01:36,144 - 399 samples (128 per mini-batch)
2022-12-13 15:01:42,907 - Epoch: [33][    4/    4]    Loss 0.416774    Top1 89.724311    Top5 99.749373    
2022-12-13 15:01:42,985 - ==> Top1: 89.724    Top5: 99.749    Loss: 0.417

2022-12-13 15:01:42,985 - ==> Confusion:
[[ 5  0  0  4  0  0  0  2  0  2]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 13  0  0  2  0  5  0]
 [ 0  0  0  0  9  0  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  3  0 19  0  0  0]
 [ 2  1  0  0  0  0  0 64  0  0]
 [ 0  0  1  4  0  0  0  1 37  0]
 [ 0  0  3  1  0  0  1  0  0 29]]

2022-12-13 15:01:43,287 - ==> Best [Top1: 90.226   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 32]
2022-12-13 15:01:43,287 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:01:43,312 - 

2022-12-13 15:01:43,312 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:02:36,983 - Epoch: [34][   29/   29]    Overall Loss 0.069564    Objective Loss 0.069564    Top1 99.264706    Top5 100.000000    LR 0.000100    Time 1.850643    
2022-12-13 15:02:37,185 - --- validate (epoch=34)-----------
2022-12-13 15:02:37,185 - 399 samples (128 per mini-batch)
2022-12-13 15:02:43,801 - Epoch: [34][    4/    4]    Loss 0.344925    Top1 90.225564    Top5 100.000000    
2022-12-13 15:02:43,873 - ==> Top1: 90.226    Top5: 100.000    Loss: 0.345

2022-12-13 15:02:43,874 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  2  0  0  0  0  0  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 13  0  0  3  0  4  0]
 [ 0  0  0  0 10  0  4  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  1  0  0  5  0 17  0  0  0]
 [ 1  1  0  0  0  0  0 65  0  0]
 [ 0  2  1  3  0  0  0  1 36  0]
 [ 0  0  1  0  1  0  1  0  0 31]]

2022-12-13 15:02:44,173 - ==> Best [Top1: 90.226   Top5: 100.000   Sparsity:0.00   Params: 369984 on epoch: 34]
2022-12-13 15:02:44,174 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:02:44,208 - 

2022-12-13 15:02:44,208 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:03:36,330 - Epoch: [35][   29/   29]    Overall Loss 0.072218    Objective Loss 0.072218    Top1 98.529412    Top5 100.000000    LR 0.000100    Time 1.797229    
2022-12-13 15:03:36,561 - --- validate (epoch=35)-----------
2022-12-13 15:03:36,561 - 399 samples (128 per mini-batch)
2022-12-13 15:03:43,250 - Epoch: [35][    4/    4]    Loss 0.401800    Top1 89.724311    Top5 100.000000    
2022-12-13 15:03:43,324 - ==> Top1: 89.724    Top5: 100.000    Loss: 0.402

2022-12-13 15:03:43,325 - ==> Confusion:
[[ 5  0  0  4  0  0  0  2  0  2]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 12  0  0  3  0  5  0]
 [ 0  0  0  0 10  0  4  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  1  0  0  4  0 18  0  0  0]
 [ 2  1  0  0  0  0  0 64  0  0]
 [ 0  2  1  3  0  0  0  1 36  0]
 [ 0  0  1  1  1  0  0  0  0 31]]

2022-12-13 15:03:43,624 - ==> Best [Top1: 90.226   Top5: 100.000   Sparsity:0.00   Params: 369984 on epoch: 34]
2022-12-13 15:03:43,624 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:03:43,648 - 

2022-12-13 15:03:43,649 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:04:35,480 - Epoch: [36][   29/   29]    Overall Loss 0.061821    Objective Loss 0.061821    Top1 96.323529    Top5 100.000000    LR 0.000100    Time 1.787190    
2022-12-13 15:04:35,709 - --- validate (epoch=36)-----------
2022-12-13 15:04:35,710 - 399 samples (128 per mini-batch)
2022-12-13 15:04:42,341 - Epoch: [36][    4/    4]    Loss 0.468203    Top1 90.225564    Top5 100.000000    
2022-12-13 15:04:42,411 - ==> Top1: 90.226    Top5: 100.000    Loss: 0.468

2022-12-13 15:04:42,412 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 12  0  0  3  0  5  0]
 [ 0  0  0  0  9  0  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  1  0  0  4  0 18  0  0  0]
 [ 0  1  0  0  0  0  0 66  0  0]
 [ 0  0  1  4  0  0  0  1 37  0]
 [ 0  0  2  0  0  1  1  0  0 30]]

2022-12-13 15:04:42,714 - ==> Best [Top1: 90.226   Top5: 100.000   Sparsity:0.00   Params: 369984 on epoch: 36]
2022-12-13 15:04:42,714 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:04:42,747 - 

2022-12-13 15:04:42,747 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:05:36,413 - Epoch: [37][   29/   29]    Overall Loss 0.053537    Objective Loss 0.053537    Top1 97.794118    Top5 100.000000    LR 0.000100    Time 1.850461    
2022-12-13 15:05:36,643 - --- validate (epoch=37)-----------
2022-12-13 15:05:36,643 - 399 samples (128 per mini-batch)
2022-12-13 15:05:43,332 - Epoch: [37][    4/    4]    Loss 0.329187    Top1 90.476190    Top5 100.000000    
2022-12-13 15:05:43,404 - ==> Top1: 90.476    Top5: 100.000    Loss: 0.329

2022-12-13 15:05:43,404 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  2  0  0  0  0  0  0]
 [ 0  1 87  0  0  0  1  0  0  0]
 [ 0  0  0 13  0  0  4  0  3  0]
 [ 0  0  0  0 11  0  3  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  1  0  0  5  0 17  0  0  0]
 [ 0  1  0  0  0  0  0 66  0  0]
 [ 1  2  1  2  0  0  0  1 36  0]
 [ 0  0  1  0  2  0  0  0  0 31]]

2022-12-13 15:05:43,705 - ==> Best [Top1: 90.476   Top5: 100.000   Sparsity:0.00   Params: 369984 on epoch: 37]
2022-12-13 15:05:43,705 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:05:43,739 - 

2022-12-13 15:05:43,739 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:06:35,915 - Epoch: [38][   29/   29]    Overall Loss 0.053966    Objective Loss 0.053966    Top1 97.794118    Top5 100.000000    LR 0.000100    Time 1.799077    
2022-12-13 15:06:36,147 - --- validate (epoch=38)-----------
2022-12-13 15:06:36,148 - 399 samples (128 per mini-batch)
2022-12-13 15:06:42,839 - Epoch: [38][    4/    4]    Loss 0.363148    Top1 89.724311    Top5 100.000000    
2022-12-13 15:06:42,913 - ==> Top1: 89.724    Top5: 100.000    Loss: 0.363

2022-12-13 15:06:42,914 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  2  0  0  0  0  0  0]
 [ 0  1 86  0  0  0  1  0  0  1]
 [ 0  0  0 13  0  0  4  0  3  0]
 [ 0  0  0  0  9  0  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  0  3  0 20  0  0  0]
 [ 4  1  0  0  0  0  0 62  0  0]
 [ 0  1  1  4  0  0  0  1 36  0]
 [ 0  0  0  0  1  0  1  0  0 32]]

2022-12-13 15:06:43,211 - ==> Best [Top1: 90.476   Top5: 100.000   Sparsity:0.00   Params: 369984 on epoch: 37]
2022-12-13 15:06:43,212 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:06:43,464 - 

2022-12-13 15:06:43,465 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:07:36,112 - Epoch: [39][   29/   29]    Overall Loss 0.054316    Objective Loss 0.054316    Top1 100.000000    Top5 100.000000    LR 0.000100    Time 1.815360    
2022-12-13 15:07:36,336 - --- validate (epoch=39)-----------
2022-12-13 15:07:36,336 - 399 samples (128 per mini-batch)
2022-12-13 15:07:43,067 - Epoch: [39][    4/    4]    Loss 0.400795    Top1 90.225564    Top5 99.749373    
2022-12-13 15:07:43,143 - ==> Top1: 90.226    Top5: 99.749    Loss: 0.401

2022-12-13 15:07:43,143 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 12  0  0  2  0  6  0]
 [ 0  0  0  0  9  1  4  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  1  0  0  4  0 17  0  1  0]
 [ 1  1  0  0  0  0  0 65  0  0]
 [ 0  2  1  2  0  0  0  1 37  0]
 [ 0  0  1  0  1  0  0  0  0 32]]

2022-12-13 15:07:43,445 - ==> Best [Top1: 90.476   Top5: 100.000   Sparsity:0.00   Params: 369984 on epoch: 37]
2022-12-13 15:07:43,445 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:07:43,470 - 

2022-12-13 15:07:43,470 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:08:37,453 - Epoch: [40][   29/   29]    Overall Loss 0.047449    Objective Loss 0.047449    Top1 98.529412    Top5 100.000000    LR 0.000010    Time 1.861400    
2022-12-13 15:08:37,680 - --- validate (epoch=40)-----------
2022-12-13 15:08:37,681 - 399 samples (128 per mini-batch)
2022-12-13 15:08:44,420 - Epoch: [40][    4/    4]    Loss 0.457506    Top1 89.724311    Top5 100.000000    
2022-12-13 15:08:44,493 - ==> Top1: 89.724    Top5: 100.000    Loss: 0.458

2022-12-13 15:08:44,494 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 86  0  0  0  1  0  0  1]
 [ 0  0  0 12  0  0  3  0  5  0]
 [ 0  0  0  0 10  0  4  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  1  0  0  4  0 18  0  0  0]
 [ 2  1  0  0  0  0  0 64  0  0]
 [ 0  2  1  3  0  0  0  1 36  0]
 [ 0  0  1  0  0  0  1  0  0 32]]

2022-12-13 15:08:44,795 - ==> Best [Top1: 90.476   Top5: 100.000   Sparsity:0.00   Params: 369984 on epoch: 37]
2022-12-13 15:08:44,795 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:08:44,820 - 

2022-12-13 15:08:44,820 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:09:37,460 - Epoch: [41][   29/   29]    Overall Loss 0.044551    Objective Loss 0.044551    Top1 100.000000    Top5 100.000000    LR 0.000010    Time 1.815079    
2022-12-13 15:09:37,698 - --- validate (epoch=41)-----------
2022-12-13 15:09:37,698 - 399 samples (128 per mini-batch)
2022-12-13 15:09:44,521 - Epoch: [41][    4/    4]    Loss 0.562578    Top1 89.974937    Top5 100.000000    
2022-12-13 15:09:44,597 - ==> Top1: 89.975    Top5: 100.000    Loss: 0.563

2022-12-13 15:09:44,597 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 87  0  0  0  1  0  0  0]
 [ 0  0  0 13  0  0  3  0  4  0]
 [ 0  0  0  0 10  0  4  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  4  0 18  0  0  0]
 [ 2  1  0  0  0  0  0 64  0  0]
 [ 0  1  1  4  0  0  0  1 36  0]
 [ 0  0  1  0  1  0  1  0  0 31]]

2022-12-13 15:09:44,916 - ==> Best [Top1: 90.476   Top5: 100.000   Sparsity:0.00   Params: 369984 on epoch: 37]
2022-12-13 15:09:44,916 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:09:44,941 - 

2022-12-13 15:09:44,941 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:10:37,709 - Epoch: [42][   29/   29]    Overall Loss 0.045311    Objective Loss 0.045311    Top1 100.000000    Top5 100.000000    LR 0.000010    Time 1.819493    
2022-12-13 15:10:37,937 - --- validate (epoch=42)-----------
2022-12-13 15:10:37,937 - 399 samples (128 per mini-batch)
2022-12-13 15:10:44,714 - Epoch: [42][    4/    4]    Loss 0.376470    Top1 90.476190    Top5 100.000000    
2022-12-13 15:10:44,785 - ==> Top1: 90.476    Top5: 100.000    Loss: 0.376

2022-12-13 15:10:44,786 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 87  0  0  0  1  0  0  0]
 [ 0  0  0 13  0  0  3  0  4  0]
 [ 0  0  0  0 10  0  4  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  1  0  0  4  0 18  0  0  0]
 [ 1  1  0  0  0  0  0 65  0  0]
 [ 0  1  1  4  0  0  0  1 36  0]
 [ 0  0  1  0  1  0  0  0  0 32]]

2022-12-13 15:10:45,087 - ==> Best [Top1: 90.476   Top5: 100.000   Sparsity:0.00   Params: 369984 on epoch: 42]
2022-12-13 15:10:45,087 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:10:45,121 - 

2022-12-13 15:10:45,121 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:11:39,426 - Epoch: [43][   29/   29]    Overall Loss 0.046629    Objective Loss 0.046629    Top1 99.264706    Top5 100.000000    LR 0.000010    Time 1.872488    
2022-12-13 15:11:39,657 - --- validate (epoch=43)-----------
2022-12-13 15:11:39,658 - 399 samples (128 per mini-batch)
2022-12-13 15:11:46,384 - Epoch: [43][    4/    4]    Loss 0.322356    Top1 90.225564    Top5 99.749373    
2022-12-13 15:11:46,457 - ==> Top1: 90.226    Top5: 99.749    Loss: 0.322

2022-12-13 15:11:46,457 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 12  0  0  3  0  5  0]
 [ 0  0  0  0 10  0  4  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  1  0  0  4  0 18  0  0  0]
 [ 2  1  0  0  0  0  0 64  0  0]
 [ 0  1  1  4  0  0  0  1 36  0]
 [ 0  0  1  0  0  0  1  0  0 32]]

2022-12-13 15:11:46,763 - ==> Best [Top1: 90.476   Top5: 100.000   Sparsity:0.00   Params: 369984 on epoch: 42]
2022-12-13 15:11:46,764 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:11:46,789 - 

2022-12-13 15:11:46,789 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:12:39,392 - Epoch: [44][   29/   29]    Overall Loss 0.045974    Objective Loss 0.045974    Top1 100.000000    Top5 100.000000    LR 0.000010    Time 1.813816    
2022-12-13 15:12:39,615 - --- validate (epoch=44)-----------
2022-12-13 15:12:39,615 - 399 samples (128 per mini-batch)
2022-12-13 15:12:46,356 - Epoch: [44][    4/    4]    Loss 0.337297    Top1 90.726817    Top5 99.749373    
2022-12-13 15:12:46,430 - ==> Top1: 90.727    Top5: 99.749    Loss: 0.337

2022-12-13 15:12:46,430 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 13  0  0  2  0  5  0]
 [ 0  0  0  0  9  0  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  3  0 19  0  0  0]
 [ 1  1  0  0  0  0  0 65  0  0]
 [ 0  1  1  4  0  0  0  1 36  0]
 [ 0  0  1  0  0  0  1  0  0 32]]

2022-12-13 15:12:46,735 - ==> Best [Top1: 90.727   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 44]
2022-12-13 15:12:46,735 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:12:46,770 - 

2022-12-13 15:12:46,770 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:13:39,479 - Epoch: [45][   29/   29]    Overall Loss 0.042338    Objective Loss 0.042338    Top1 97.794118    Top5 100.000000    LR 0.000010    Time 1.817480    
2022-12-13 15:13:39,704 - --- validate (epoch=45)-----------
2022-12-13 15:13:39,705 - 399 samples (128 per mini-batch)
2022-12-13 15:13:46,370 - Epoch: [45][    4/    4]    Loss 0.327792    Top1 90.225564    Top5 100.000000    
2022-12-13 15:13:46,445 - ==> Top1: 90.226    Top5: 100.000    Loss: 0.328

2022-12-13 15:13:46,445 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 12  0  0  3  0  5  0]
 [ 0  0  0  0  9  0  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  4  0 18  0  0  0]
 [ 2  1  0  0  0  0  0 64  0  0]
 [ 0  0  1  4  0  0  0  1 37  0]
 [ 0  0  1  0  0  0  1  0  0 32]]

2022-12-13 15:13:46,748 - ==> Best [Top1: 90.727   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 44]
2022-12-13 15:13:46,749 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:13:46,774 - 

2022-12-13 15:13:46,774 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:14:40,844 - Epoch: [46][   29/   29]    Overall Loss 0.052001    Objective Loss 0.052001    Top1 99.264706    Top5 100.000000    LR 0.000010    Time 1.864417    
2022-12-13 15:14:41,050 - --- validate (epoch=46)-----------
2022-12-13 15:14:41,050 - 399 samples (128 per mini-batch)
2022-12-13 15:14:47,771 - Epoch: [46][    4/    4]    Loss 0.311081    Top1 90.476190    Top5 99.749373    
2022-12-13 15:14:47,845 - ==> Top1: 90.476    Top5: 99.749    Loss: 0.311

2022-12-13 15:14:47,845 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 12  0  0  3  0  5  0]
 [ 0  0  0  0 10  0  4  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  4  0 18  0  0  0]
 [ 1  1  0  0  0  0  0 65  0  0]
 [ 0  1  1  4  0  0  0  1 36  0]
 [ 0  0  1  0  0  0  1  0  0 32]]

2022-12-13 15:14:48,146 - ==> Best [Top1: 90.727   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 44]
2022-12-13 15:14:48,146 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:14:48,171 - 

2022-12-13 15:14:48,172 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:15:41,064 - Epoch: [47][   29/   29]    Overall Loss 0.045250    Objective Loss 0.045250    Top1 98.529412    Top5 100.000000    LR 0.000010    Time 1.823790    
2022-12-13 15:15:41,291 - --- validate (epoch=47)-----------
2022-12-13 15:15:41,292 - 399 samples (128 per mini-batch)
2022-12-13 15:15:47,987 - Epoch: [47][    4/    4]    Loss 0.380415    Top1 89.974937    Top5 99.749373    
2022-12-13 15:15:48,061 - ==> Top1: 89.975    Top5: 99.749    Loss: 0.380

2022-12-13 15:15:48,062 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 87  0  0  0  1  0  0  0]
 [ 0  0  0 12  0  0  3  0  5  0]
 [ 0  0  0  0  9  0  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  4  0 18  0  0  0]
 [ 2  1  0  0  0  0  0 64  0  0]
 [ 0  0  1  4  0  0  0  1 37  0]
 [ 0  0  1  0  0  0  1  0  0 32]]

2022-12-13 15:15:48,587 - ==> Best [Top1: 90.727   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 44]
2022-12-13 15:15:48,587 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:15:48,612 - 

2022-12-13 15:15:48,612 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:16:41,449 - Epoch: [48][   29/   29]    Overall Loss 0.042953    Objective Loss 0.042953    Top1 99.264706    Top5 99.264706    LR 0.000010    Time 1.821851    
2022-12-13 15:16:41,672 - --- validate (epoch=48)-----------
2022-12-13 15:16:41,673 - 399 samples (128 per mini-batch)
2022-12-13 15:16:48,440 - Epoch: [48][    4/    4]    Loss 0.300221    Top1 90.476190    Top5 99.749373    
2022-12-13 15:16:48,513 - ==> Top1: 90.476    Top5: 99.749    Loss: 0.300

2022-12-13 15:16:48,513 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 87  0  0  0  1  0  0  0]
 [ 0  0  0 12  0  0  3  0  5  0]
 [ 0  0  0  0 10  1  3  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  1  0  0  4  0 18  0  0  0]
 [ 0  1  0  0  0  0  0 66  0  0]
 [ 0  1  1  4  0  0  0  1 36  0]
 [ 0  0  1  0  1  0  0  0  0 32]]

2022-12-13 15:16:48,821 - ==> Best [Top1: 90.727   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 44]
2022-12-13 15:16:48,821 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:16:48,847 - 

2022-12-13 15:16:48,847 - Training epoch: 3592 samples (128 per mini-batch)
2022-12-13 15:17:43,200 - Epoch: [49][   29/   29]    Overall Loss 0.043924    Objective Loss 0.043924    Top1 98.529412    Top5 100.000000    LR 0.000010    Time 1.874158    
2022-12-13 15:17:43,430 - --- validate (epoch=49)-----------
2022-12-13 15:17:43,431 - 399 samples (128 per mini-batch)
2022-12-13 15:17:50,127 - Epoch: [49][    4/    4]    Loss 0.349748    Top1 90.225564    Top5 99.749373    
2022-12-13 15:17:50,202 - ==> Top1: 90.226    Top5: 99.749    Loss: 0.350

2022-12-13 15:17:50,203 - ==> Confusion:
[[ 6  0  0  2  0  0  0  2  0  3]
 [ 0 54  0  1  0  0  0  0  1  0]
 [ 0  1 88  0  0  0  0  0  0  0]
 [ 0  0  0 12  0  0  3  0  5  0]
 [ 0  0  0  0  9  0  5  0  0  0]
 [ 0  0  0  0  0 40  0  0  0  0]
 [ 0  0  0  1  4  0 18  0  0  0]
 [ 2  1  0  0  0  0  0 64  0  0]
 [ 0  0  1  4  0  0  0  1 37  0]
 [ 0  0  1  0  0  0  1  0  0 32]]

2022-12-13 15:17:50,506 - ==> Best [Top1: 90.727   Top5: 99.749   Sparsity:0.00   Params: 369984 on epoch: 44]
2022-12-13 15:17:50,506 - Saving checkpoint to: logs/2022.12.13-142739/qat_checkpoint.pth.tar
2022-12-13 15:17:50,532 - --- test ---------------------
2022-12-13 15:17:50,532 - 908 samples (128 per mini-batch)
2022-12-13 15:18:04,999 - Test: [    8/    8]    Loss 0.534888    Top1 82.599119    Top5 99.449339    
2022-12-13 15:18:05,059 - ==> Top1: 82.599    Top5: 99.449    Loss: 0.535

2022-12-13 15:18:05,060 - ==> Confusion:
[[29  4  0  5  1  0  0  9  1  1]
 [ 2 97  0  0  0  0  0  0  1  0]
 [ 0  0 94  0  0  0  0  1  1  4]
 [ 5  0  1 48  1  0  3  4 20  4]
 [ 0  0  0  1 64  5 15  0  0  1]
 [ 0  0  0  0  5 94  0  1  0  0]
 [ 0  1  0  3 23  0 49  1  9  0]
 [ 2  1  0  1  1  0  1 94  0  0]
 [ 0  0  0 14  0  0  0  0 86  0]
 [ 0  1  1  0  3  0  0  0  0 95]]

2022-12-13 15:18:05,063 - 
2022-12-13 15:18:05,063 - Log file for this run: /home/ec2-user/SageMaker/pcd-max/training/logs/2022.12.13-142739/2022.12.13-142739.log
